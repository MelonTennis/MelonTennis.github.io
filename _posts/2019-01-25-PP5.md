---
dzzlayout: post
title: Parallel Architecture & Programing V
subtitle: 15618 PP5 Performance Evaluation
date: 2019-01-25
categories: Note
tags: [PP]
catalog: true
header-img: "img/ctc1.jpeg"
---

## Parallel Architecture & Programing 伍

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

~~工作使我自闭，丧丧丧。 甚至不知道到底是data烂，还是我烂。算了，就算我的吧，随便了。今天听说我研究生时期鼓励过我的学长回国了，可惜了了还没当面感谢呢～大家纷纷回国过年，快乐都是别人的我啥都没有🐶~~

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/baddata.png" style="zoom:65%">

### Size for scaling

* There can be complex interactions between the size of the problem and the size of the parallel computer
  * Can impact load balance, overhead, arithmetic intensity, locality of data access
  * Effects can be dramatic and application dependent

* Can be desirable to scale problem size as machine sizes grow

比如这两个图：

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/sizeproblem.png" style="zoom:70%">

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/sizeproblem1.png" style="zoom:65%">

* Too small a problem
  * Parallelism overheads dominate parallelism benefits
  * Problem size may be appropriate for small machines, but inappropriate for large ones

* Too large a problem
  * Key working set may not “fit” in small machine
  * When problem working set “fits” in a large machine but not small one, super-linear speedups can occur

**Common Scaling Terminology**

* Strong scaling
  * Runtime of X on P processors, vs. of X on 1 processor
  * Goal = P
* Weak scaling
  * Runtime of (P*X) on P processors, vs. of X on 1 processor
  * Goal = 1.0

#### Scaling constraints

**Application-oriented scaling properties**

* Particles per processor
* Transactions per processor

**Resource-oriented scaling properties**

* Problem constrained scaling
  * Use a parallel computer to solve the same problem faster
  * Speedup =  $$\frac{time\ 1\  processor}{time\ P\ processors}​$$
* Time constrained scaling
  * Completing more work in a fixed amount of time
  * Execution time kept fixed as the machine (and problem) scales
  * Speedup =  $$\frac{work\ done\ by\ P\  processors}{work\ done\ by\ 1\ processor}​$$
* Memory constrained scaling
  * Run the largest problem possible without overflowing main memory
  * Memory per processor is held fixed
  * Neither work nor execution time are held constant
  * Speedup =  $$\frac{work(P\  processors)\ *\ time(1\ processor)}{time(P\  processors)\ *\ work(1\ processor)}$$ = $$\frac{work\ per\ unit\ time\ on\ P\ processors}{work\ per\ unit\ time\ on\ 1\ processor}​$$

 还是那个2D grid solver的例子：

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/grid2dscale.png" style="zoom:70%">

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/grid2dscale1.png" style="zoom:70%">

~~想起来考前复习算了好久这些，每个都算了orz 所以这个故事告诉我不论学的多差只要不放弃自己还是能过的（打A是不能打A了，PP我能打A，🐷都能上🌲~~

**Challenges of scaling**

* Preserve ratio of time spent in different program phases
* Preserve important behavioral characteristics
* Preserve contention and communication patterns
* Preserve scaling relationships between problem parameters

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/scaleadvice.png" style="zoom:65%">

~~想回家过年。~~