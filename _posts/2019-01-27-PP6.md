---
dzzlayout: post
title: Parallel Architecture & Programing VI
subtitle: 15618 PP6 Cache Coherence
date: 2019-01-27
categories: Note
tags: [PP]
catalog: true
header-img: "img/ctc1.jpeg"
---

## Parallel Architecture & Programing é™†

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

~~å°±è¿˜è§‰å¾—æ•°æ®é›†å°±æ˜¯ä¸ªåƒåœ¾ï¼Œæ ¹æœ¬ä¸æ˜¯imblanceæˆ–è€…å…¶ä»–ä»€ä¹ˆé—®é¢˜ï¼Œå­¦ä¸å‡ºæ¥çš„:) ä¸€è¾¹trainåæ­£ä¹Ÿtrainä¸å‡ºæ¥çš„ç½‘ç»œï¼Œä¸€è¾¹å­¦ä¹ Cache Coherenceï¼Œæˆ‘å¤±å¿†ï¼Œæˆ‘ä¸ä¼šã€‚éƒ½æ˜¯å‡çš„ğŸ¤¦â€â™‚ï¸ã€‚æ¯å¤©å·¥ä½œéƒ½è‡ªé—­å•Šå•Šå•Šå•Šå•Šå•Šå•Šæˆ‘æ˜¯ä¸€åªåœŸæ‹¨é¼ äº†å¤©å“ªæˆ‘è‡ªé—­åˆ°åƒè¾£æ¡ï¼Œåˆåƒäº†ä¸€ä¸ªæ©™å­ã€‚æˆ‘è‡ªé—­äº†ã€‚æƒ³äº†æƒ³å¯èƒ½è¿˜æ˜¯è¦åˆ·é¢˜ï¼Œåˆå›åˆ°å­¦ç”Ÿæ—¶ä»£é‚£æ—¶å€™å¤©å¤©åˆ·é¢˜ï¼Œå¬å°åŠï¼Œç­‰æˆ‘å¤ä¹ å®ŒPPæˆ‘å°±ä¸å¬äº†ã€‚~~

### Snooping-Based Cache Coherence 

#### Cache overview

513çš„å†…å®¹ï¼Œä¸€æ¡é•¿è¿™æ ·çš„cache lineï¼š

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/cacheline.png" style="zoom:70%">

**Writing policies**

[wiki](https://en.wikipedia.org/wiki/Cache_(computing))

Write back vs. Write through cache

- Write-through: write is done synchronously both to the cache and to the backing store
- Write-back:  writing is done only to the cache. The write to the backing store is postponed until the modified content is about to be replaced by another cache block

Allocate vs. Write-no-allocate cache

- Write allocate: data at the missed-write location is loaded to cache, followed by a write-hit operation. In this approach, write misses are similar to read misses.
- No-write allocate: data at the missed-write location is not loaded to cache, and is written directly to the backing store. In this approach, data is loaded into the cache on read misses only

ä¸€ä¸ªå…±äº«å†…å­˜çš„å¤šæ ¸å¤„ç†å™¨ï¼š

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/sharememorymultip.png" style="zoom:80%">

* Processors issue load and store instructions

* Reading a value at address X should return the last value written to address X by any processor

Cache coherence problem: processors can observe different values for the same memory location

Assume the initial value stored at address X is 0 and write-back cache behavior:

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/cachebehavior.png" style="zoom:85%">

~~æˆ‘ä¹Ÿæƒ³ä¸é€šå½“æ—¶ä¸ºä½•ä¸€åº¦çœ‹ä¸æ‡‚è¿™ä¸ªå›¾~~

* Memory coherence problem exists because there is both global storage (main memory) and per-processor local storage (processor caches) implementing the abstraction of a single shared address space

å¯¹äºsingle CPU systemï¼š

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/singlecpusystem.png" style="zoom:80%">

* [Direct memory access(DMA)](https://zh.wikipedia.org/wiki/%E7%9B%B4%E6%8E%A5%E8%A8%98%E6%86%B6%E9%AB%94%E5%AD%98%E5%8F%96)
* Common solutions:
  * CPU writes to shared buffers using uncached stores
  * OS support

**Coherence**

Definition ï¼š

* Obeys program order: A read by processor P to address X that follows a write by P to address X, should return the value of the write by P (assuming no other processor wrote to X in between)

* **Write propagation**: A read by processor P1 to address X that follows a write by processor P2 to X returns the written value(assuming no other write to X occurs in between)
* **Write serialization**
  *  Writes to the same address are serialized: two writes to address X by any two processors are observed in the same order by all processors

Implementment:

* Software-based solutions
* Hardware-based solutions
  * Snooping based coherence implementations ç›‘å¬å¼ç¼“å­˜ä¸€è‡´æ€§
  * Directory based coherence implementations ç›®å½•å¼ç¼“å­˜ä¸€è‡´æ€§

#### Snooping cache-coherence schemes

* Main idea: all coherence-related activity is broadcast to all processors
* Cache controllers monitor memory operations, and react accordingly to maintain memory coherence

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/snoopscheme.png" style="zoom:75%">

å¯¹äºWrite-through cachesï¼š

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/writethroughcache.png" style="zoom:65%">

* Cache line states: Valid/Invalid
* Processor operations: Read/ Write (local processor)
* Bus transactions: Bus read/Bus write (remote caches)

* Requirements of the interconnect:
  * All write transactions visible to all cache controllers
  * All write transactions visible to all cache controllers in the same order

è¿™ä¸ªçŠ¶æ€å›¾é‡Œcache lineæœ‰ä¸¤ç§çŠ¶æ€ï¼ŒInvalidè¡¨ç¤ºæœ¬åœ°æ•°æ®å¤±æ•ˆï¼Œéœ€è¦ä»ä¸»å­˜æ›´æ–°ã€‚æ¯ä¸ªcache controlleræ§åˆ¶æœ¬åœ°è¯»å†™æ“ä½œï¼Œä¹Ÿèƒ½å¤ŸçŸ¥é“å…¶ä»–cache controlleræ§åˆ¶çš„remoteè¯»å†™æ“ä½œã€‚Cacheåœ¨Validæƒ…å†µä¸‹æœ¬åœ°è¯»æ“ä½œä¸ä¼šæ”¹å˜çŠ¶æ€ï¼Œå†™æ“ä½œä¼šå¼•èµ·Bus writeé€šçŸ¥å…¶ä»–controlleræ”¹å˜cache lineçŠ¶æ€ã€‚Write-throughçš„æ¯ä¸€ä¸ªå†™æ“ä½œéƒ½ä¼šå†™å…¥ä¸»å­˜ï¼Œå…·æœ‰å¾ˆé«˜çš„å¸¦å®½è¦æ±‚ï¼Œå› æ­¤æ˜¯ä½æ•ˆçš„ã€‚

å¯¹äºWrite-back cachesï¼š

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/writebackcache.png" style="zoom:75%">

* Exclusive: cache is only cache with a valid copy of line
* Owner: cache is responsible for supplying the line to other processors when they attempt to load it from memory

##### Invalidation-based write back

Key ideas:

* A line in the â€œexclusiveâ€ state can be modified without notifying the other caches
* Processor can only write to lines in the exclusive state
* When cache controller snoops a request for exclusive access to line it contains it must invalidate the line in its own cache

**MSI invalidation protocol**

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/MSI.png" style="zoom:65%">

* Cache line states: 
  * Invalid(I)
  * Shared(S): line valid in one or more caches
  * Modified(M): line valid in exactly one cache (dirty/exclusive)
* Processor operations: Read/Write
* Bus transactions:
  * BusRd: obtain copy of line with no intent to modify
  * BusRdX: obtain copy of line with intent to modify
  * flush: write dirty line out to memory

å½“Cache lineçš„çŠ¶æ€ä¸ºMæ—¶ï¼Œlocal processorå¯ä»¥æ›´æ”¹è¿™æ¡cache lineè€Œä¸ç”¨é€šçŸ¥å…¶ä»–cacheã€‚å½“cacheçš„çŠ¶æ€ä¸æ˜¯Mæ—¶ï¼Œprocessorä¸å¯ä»¥å†™å…¥è¿™ä¸€æ¡cacheï¼Œè€Œæ˜¯é€šè¿‡bus read-exclusiveå°†cacheçš„çŠ¶æ€æ”¹ä¸ºMï¼Œå¹¶å‘ŠçŸ¥å…¶ä»–cacheå³å°†æ›´æ”¹ã€‚å½“cache controlleræ£€æµ‹åˆ°remote read-exclusiveæ“ä½œï¼Œè¿™ä¸€æ¡cache lineçš„çŠ¶æ€ä¼šå˜æˆInvalidã€‚é€šè¿‡bus readå’Œbus read-exclusiveï¼ŒMSIå¯ä»¥æ»¡è¶³write propagationå’Œwrite serializationã€‚

**MSEI invalidation protocol**

MSEI protocolé€šè¿‡åŠ å…¥Eè¿™ä¸€çŠ¶æ€æ¥å‡å°‘MSI protocalä¸­interconnect transactionsçš„ä½æ•ˆé—®é¢˜ã€‚

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/MSEI.png" style="zoom:60%">

E: â€œexclusive cleanâ€ ç‹¬å ä¸”ä¸ä¸»å­˜ä¸€è‡´

* Line has not been modified, but only this cache has a copy of the line
* Decouples exclusivity from line ownership
* Upgrade from E to M does not require an interconnect transaction

CacheçŠ¶æ€ç”±Eåˆ°Mæ— éœ€æ€»çº¿è¯»å†™ï¼ŒèŠ‚çœäº†å¸¦å®½ã€‚æ›´å¤šçš„çŠ¶æ€èƒ½å¤Ÿæå‡æ•ˆç‡ï¼ŒåŒæ—¶ä¹Ÿæé«˜äº†å¤æ‚åº¦ï¼Œæ¯”å¦‚MESIFå’ŒMOESI.

##### Update-based protocols

å¯¹äºInvalidation-based protocol, cacheå¿…é¡»ç‹¬å ä¸€æ¡cache lineæ‰å¯ä»¥å†™å…¥ï¼Œå…¶ä»–cacheéœ€è¦invalidate copies. å¯¹äºUpdate-based protocolï¼Œcacheå¯ä»¥é€šè¿‡å¹¿æ’­æ›´æ–°æ‰€æœ‰copiesæ¥å†™å…¥ã€‚

**Dragon write-back update protocol**

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/dragonwriteback.png" style="zoom:60%">

* Cache states:
  * Exclusive clean(E): only one cache has line, memory up-to-date
  * Shared-clean(SC): multiple caches may have line, and memory may or may not be up to date
  * Shared-modified(SM): multiple caches may have line, memory not up to date
    * Only one cache can be in this state for a given line (but others can be in SC)
    * Cache with line in SM state is â€œownerâ€ of data. Must update memory upon eviction
  * Modified(M): only one cache has line, it is dirty, memory is not up to date
    * Cache is owner of data. Must update memory upon replacement

* Processor actions: Read/Write/ReadMiss/WriteMiss
* Bus transactions: 
  * Bus read
  * flush: provide entire line to others
  * Bus update: provide partial line to others
* Overhead if:
  * Data just sits in caches
  * Application performs many writes before the next read

##### Summary

* The cache coherence problem exists because the abstraction of a single shared address space is not implemented by a single storage unit
* Main idea of snooping-based cache coherence: whenever a cache operation occurs that could affect coherence, the cache controller broadcasts a notification to all other cache controllers
  * Challenge for HW architects: minimizing overhead of coherence implementation
  * Challenge for SW developers: be wary of artifactual communication due to coherence protocol (e.g., false sharing)
* Scalability of snooping implementations is limited by ability to broadcast coherence messages to all caches

#### False Sharing

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/falsesharing.png" style="zoom:80%">

* Condition where two processors write to different addresses, but addresses map to the same cache line
* Cache line â€œping-pongsâ€ between caches of writing processors, generating significant amounts of communication due to the coherence protocol
* No inherent communication, this is entirely artifactual communication

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/falsesharing1.png" style="zoom:65%">

ä¼ªå…±äº«å‘ç”Ÿåœ¨å¤šä¸ªprocessorä¿®æ”¹åŒä¸€cache lineçš„æ•°æ®ï¼Œä¸ºäº†ä¿è¯cache coherenceï¼Œè¿™æ¡cache lineçš„çŠ¶æ€ä¸æ–­æ”¹å˜ï¼Œéœ€è¦é€šè¿‡ä¸»å­˜ä¸­è¯»å†™æ¥æ›´æ–°ã€‚

### Directory-Based Cache Coherence

ç›‘å¬å¼é€šè¿‡å¹¿æ’­ä¸€è‡´æ€§æ¶ˆæ¯æ¥å†³å®šå…¶ä»–cacheä¸­cache lineçš„çŠ¶æ€ã€‚å°†cache lineçš„çŠ¶æ€å­˜å‚¨åœ¨ç›®å½•ä¸­å¯ä»¥å‡å°‘æ€»çº¿çš„ä½¿ç”¨ã€‚

ä¸€ä¸ªåˆ†å¸ƒå¼çš„ç›®å½•ï¼š

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/distributeddirectory.png" style="zoom:60%">

* Home node: node with memory holding the corresponding data for the line
* Requesting node: node containing processor requesting line
* Ring-based schemes can be much simpler than point-to-point communication

Read missçš„æƒ…å†µï¼š

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/readmiss.png" style="zoom:60%">

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/readmiss1.png" style="zoom:60%">

ç®€è€Œè¨€ä¹‹ï¼Œå¯¹äºè¯»æ“ä½œhome nodeçš„directoryä¸­å­˜ç€cache lineçš„ä¿¡æ¯ï¼Œå¦‚æœcleanå°±è¿”å›å†…å®¹å¹¶ä¸”æ›´æ–°ç›®å½•ï¼Œå¦‚æœdirtyå°±è¿”å›æœ€æ–°çš„cache lineæ‰€å­˜åœ¨çš„nodeï¼Œè¿™ä¸ªnodeæ”¶åˆ°requeståä¼šè¿”å›cache lineçš„å†…å®¹ç»™request nodeå’Œhome nodeï¼Œcache lineåœ¨homeä¸­çš„çŠ¶æ€å˜ä¸ºcleanã€‚

Write missçš„æƒ…å†µåŒç†ï¼š

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/writemiss.png" style="zoom:60%">

Advantage of directories:

* On reads, directory tells requesting node exactly where to get the line from
* On writes, the advantage of directories depends on the number of sharers
  * If all caches are sharing data, all caches must be communicated with 

* Directories are useful for limiting coherence traffic

Challenge: reducing overhead of directory storage

* Use hierarchies of processors or larger line sizes
* Limited pointer schemes: exploit fact the most processors not sharing line
* Sparse directory schemes: exploit fact that most lines are not in cache

### Deadlock & Livelock & Starvation

**Deadlock**  æ­»é”

A system has outstanding operations to complete, but no operation can make progress.

Required conditions:

 * Mutual exclusion: one processor can hold a given resource at once
 * Hold and wait: processor must hold the resource while waiting for other resources needed to complete an operation
 * No preemption: processors donâ€™t give up resources until operation they wish to perform is complete
 * Circular wait: waiting processors have mutual dependencies 

**Livelock** æ´»é”

A system is executing many operations, but no thread is making meaningful progress.

**Starvation** é¥¥é¥¿

A system is making overall progress, but some processes make no progress. Starvation is usually not a permanent state.

~~å°±è¿™æ ·å§ï¼Œä»Šå¤©ä¸æ˜¯å¾ˆæœ‰å¥½å¥½å­¦ä¹ è¿™ä¸ªä¸œè¥¿çš„å…´è‡´ã€‚æœ€åç”¨ä¸€å¼ pptæ”¶å°¾ï¼Œå°±è¿™æ ·å§ã€‚~~

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/classexercise.png" style="zoom:60%">

### Reference

[Cache - wikipedia](https://en.wikipedia.org/wiki/Cache_(computing))

[CPU cacheç»“æ„å’Œç¼“å­˜ä¸€è‡´æ€§](http://www.voidcn.com/article/p-hnmsretm-uo.html)

[Avoiding and Identifying False Sharing Among Threads](https://software.intel.com/en-us/articles/avoiding-and-identifying-false-sharing-among-threads/)