---
layout: post
title: Parallel Architecture & Programing I
subtitle: 15618 PP1 - Basic & HW/SW Implementation
date: 2018-05-23
categories: Note
tags: [PP, 15618]
catalog: true
---

## Parallel Architecture & Programing 壹

直到毕业我才写总结笔记，为我自己的颓废表示羞耻\_(:з」∠)\_ 学这一部分的时候我还分不清GPU和CPU…… 首先就先介绍了相关基础概念和硬件&软件方面的相关实现。

### Forms of parallelism

#### Parallel Execution 并行执行

（想想我居然连编译器是做什么的都不知道:) 有机会上一下Compiler就好啦ಥ_ಥ

以Taylor展开的example program举例：

```
void sinx(int N, int terms, float* x, float* result)
{
   for (int i=0; i<N; i++)
   {
	float value = x[i];
	float numer = x[i] * x[i] * x[i]; intdenom=6; //3!
	int sign = -1;
    for (int j=1; j<=terms; j++)
    {
       value += sign * numer / denom;
       numer *= x[i] * x[i];
       denom *= (2*j+2) * (2*j+3);
       sign *= -1;
    }
    result[i] += value;
  }
}
```

**Compiler**: input: programs, output: sequence of instructions

**Processors**: run sequence of instructions, which means loading instruction from memory, figuring out what it means(decode), and having component act.

Simple Processor 单核处理器的基本结构：

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/masterglecore/sin.png" style="zoom:50%">

ALU\*1, 1Execution Context\*1, execute one instruction per clock

Superscalar processor 超标量处理器：					
<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/superscalar.png" style="zoom:50%">

Decode\*2, ALU\*2, can run two instructions same time(if dependent)

加速：

* 单核芯片通过增减transistor来增减运行instruction的速度，more transistors = hold more data = large cache
* multiple core(each core is slower than simple core adding transistors)
* change program by using *pthread* to achieve parallisum 
* change program by using data parallel expression

##### SIMD Processing

**SIMD**: single instruction, multiple data

Basic idea: adding ALUs to increase compute capability

Explicit SIMD”: SIMD parallelization is performed at compile time

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/SIMD.png" style="zoom:50%">

* Hardware (not compiler) is responsible for simultaneously executing the sameinstruction from multiple instances on different data on SIMD ALUs
* With one decode and multiple ALU, simply broadcast instruction to all ALUs and execute on all ALUs in parallel

对于example code相当于同时对于cache中的array，同时运行相同的程序，calculate by vector (HW1的vector算法很tricky表示并想不出来∠( ᐛ 」∠)＿

Vector program(width=8):

```
void sinx(int N, int terms, float* x, float* result)
{
   float three_fact = 6;  // 3!
   for (int i=0; i<N; i+=8) // calculate by vector, width=8
   {
      __m256 origx = _mm256_load_ps(&x[i]);
      __m256 value = origx;
      __m256 numer = _mm256_mul_ps(origx, _mm256_mul_ps(origx, origx));
      __m256 denom = _mm256_set1ps(three_fact);
      float sign = -1;
      for (int j=1; j<=terms; j++)
      {
         // value += sign * numer / denom
         __m256 tmp = _mm256_div_ps(_mm256_mul_ps(_mm256_set1ps(sign), numer), denom);
         value = _mm256_add_ps(value, tmp);
         numer = _mm256_mul_ps(numer, _mm256_mul_ps(origx, origx));
         denom = _mm256_mul_ps(denom, _mm256_set1ps((2*j+2) * (2*j+3)));
         sign *= -1;
}
      _mm256_store_ps(&result[i], value);
   }
}
```

SIMD applies same instruction to all elements simultaneously. So coherent execution is necessary for processing resources.

Possible bottleneck: **divergent execution**

也就是说对于vector中的每一个element，SIMD要求执行相同的指令。所以当遇到if condition的时候会造成资源的浪费。

**Condition**: mask of ALU

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/simdmask.png" style="zoom:50%">

Worst case: 1/8 peak performance

Solution: change program to reach full performance

##### 三种Parallel Execution对比:

* Multi-core 多核：multiple processing core
  * thread level parallelism：simultaneously execute different instrection stream on each core
  * SW decides to create threads (by pthreads)
* SIMD: multiple ALU
  * vectorization done by complier(explicit SIMD) or at runtion by HW
  * dependencies known prior to execution
  * Superscalar: instruction level parallelism (ILP) on one core
  * parallel by HW during execution

#### Accessing memory

访问内存的效率会对程序的整体效率产生很大的影响。（hw2循环里疯狂访问，笑

**Memory latency**：The amount of time for a memory request (e.g., load, store) from aprocessor to be serviced by the memory system

**Memory bandwidth**: The rate at which the memory system can provide data to a processor

Stalls: A processor “stalls” when it cannot run the next instruction in an instruction stream because of a dependency on a previous instruction




​				
​			
​		
​					
​			
​		
​	
