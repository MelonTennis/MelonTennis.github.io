---
dzzlayout: post
title: Parallel Architecture & Programing VIII
subtitle: 15618 PP8 Synchronization Implementing
date: 2019-02-01
categories: Note
tags: [PP]
catalog: true
header-img: "img/ctc1.jpeg"
---

## Parallel Architecture & Programing VIII

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

~~ğŸ‹ğŸ‹ğŸ‹åŒ…å›´ç€æˆ‘ï¼Œä»Šå¤©ä¹Ÿè¦åŠ æ²¹é¸­ã€‚WFHäº†æ‰€ä»¥æ²¡æœ‰è‡ªé—­ï¼Œç”šè‡³æ²¡æœ‰å·¥ä½œï¼Œè€Œæ˜¯åœ¨å­¦ä¹ å¦‚ä½•å®ç°åŒæ­¥ï¼Œè™½ç„¶æ²¡å•¥ç”¨ã€‚å•Šå•Šå•Šå•Šå•Šå•Šå•Šå†…å¿ƒååˆ†éš¾å—äº†ã€‚å•Šéš¾å—\_(:Ğ·ã€âˆ )_æˆ‘æ˜¯æƒ³å¥½å¥½å·¥ä½œçš„~~

### Implemenging Locks

**Primitives for ensuring mutual exclusion**

* Locks
* Atomic primitives
* Transactions

**Primitives for event signaling**

* Barriers
* Flags

**Three phases of a synchronization event**

* Acquire method
* Waiting algorithm
  * Busy waiting (spinning)
    * Scheduling overhead is larger than expected wait time
    * Processorâ€™s resources not needed for other tasks
  * Blocking: if progress cannot be made because a resource cannot be acquired, it is desirable to free up execution resources for another thread
* Release method

**Desirable lock performance**

* Low latency: If lock is free and no other processors are trying to acquire it, a processor should

  be able to acquire the lock quickly

* Low interconnect traffic: If all processors are trying to acquire lock at once, they should acquire the lock in succession with as little traffic as possible
* Scalability: Latency / traffic should scale reasonably with number of processors
* Low storage cost
* Fairness: Avoid starvation or substantial unfairness

**Test and set lock**

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/testandset.png" style="zoom:60%">

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/testandset1.png" style="zoom:62%">

Characteristicsï¼š

*  Slightly higher latency than test-and-set in uncontended case
* Generates much less interconnect traffic
  * One invalidation, per waiting processor, per lock release (O(P) invalidations)
  * O(P2) interconnect traffic if all processors have the lock cached
  * Test-and-set lock generated one invalidation per waiting processor per test
* More scalable (due to less traffic)
* Storage cost unchanged (one int)
* Still no provisions for fairness

Test-and-set lock with back offï¼š

* Upon failure to acquire lock, delay for awhile before retrying

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/testandset2.png" style="zoom:68%">

* Same uncontended latency as test-and-set, but potentially higher latency under contention
* Generates less traffic than test-and-set
* Improves scalability (due to less traffic)
* Storage cost unchanged
* Exponential back-off can cause severe unfairness (newer requesters back off for shorter intervals)
* Main problem with test-and-set style locks: upon release, all waiting processors attempt to acquire lock using test-and-set

~~æƒ³å›å·¥å¤§åƒå¹´å¤œé¥­~~ Test and set lockä¿è¯å…±äº«èµ„æºåœ¨ä»»ä¸€æ—¶åˆ»åªæœ‰ä¸€ä¸ªé”çš„æ‹¥æœ‰è€…ï¼Œå…¶ä»–å¤„ç†å™¨busy waiting. 

**Ticket lock**

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/ticketlock.png" style="zoom:65%">

* No atomic operation needed to acquire the lock (only a read)
* Only one invalidation per lock release (O(P) interconnect traffic)

**Array-based lock**

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/arraybaselock.png" style="zoom:65%">

* Each processor spins on a different memory address 
* Utilizes atomic operation to assign address on attempt to acquire

* O(1) interconnect traffic per release, but lock requires space linear in P
* The atomic circular increment is a more complex operation (higher overhead)

 **Queue-based Lock (MCS lock)**

* Create a queue of waiters
  * Each thread allocates a local space on which to wait

* Pseudo-code:
  * Glock â€“ global lock
  * Mlock â€“my lock (state, next pointer)

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/msclock.png" style="zoom:70%">

### Implementing Barriers

**Centralized barrier**

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/centralbarrier.png" style="zoom:65%">

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/centralbarrier1.png" style="zoom:65%">

* O(P) traffic on interconnect per barrierï¼š
  * All threads: 2P write transactions to obtain barrier lock and update counter
  * Last thread: 2 write transactions to write to the flag and reset the counter

* Still serialization on a single shared lock
  * So span (latency) of entire operation is O(P)
  * Optimizationï¼šTree implementation

**Tree implementation of barrier**

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/treebarrier.png" style="zoom:65%">

* Combining trees make better use of parallelism in interconnect topologies
  * lg(P) span (latency)
  * Strategy makes less sense on a bus (all traffic still serialized on single shared bus)

* Barrier acquire: when processor arrives at barrier, performs increment of parent counter
* Barrier release: beginning from root, notify children of release

### Fine-grained locking

* Use fine-grained locking to reduce contention (maximize parallelism) in operations on shared data structures
  * But fine-granularity can increase code complexity (errors) and increase execution overhead

ç»†ç²’åº¦åŒæ­¥ï¼Œä¸¾ä¸ªå‘æœ‰åºé“¾è¡¨ä¸­æ’å…¥èŠ‚ç‚¹çš„ä¾‹å­ï¼š

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/simultaneousinsert.png" style="zoom:70%">

å¤šä¸ªçº¿ç¨‹åŒæ—¶ä¿®æ”¹å¯¼è‡´ä¸¢å¤±èŠ‚ç‚¹ã€‚

Solution 1: protect the list with a single lock

 <img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/singlelock.png" style="zoom:80%">

* Good: Simple
* Bad: Operations on the data structure are serialized

Solution 2: fine-grained locking

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/finegrainedlock.png" style="zoom:85%">

* Goal: enable parallelism in data structure operations
  * Reduces contention for global data structure lock
  * In linked-list example: a single monolithic lock is overly conservative

* Challenge: tricky to ensure correctness
* Costs
  * Overhead of taking a lock each traversal step
  * Extra storage cost 

æ¯ä¸ªnodeéƒ½æ‹¥æœ‰è‡ªå·±çš„é”ï¼Œæˆ–è®¸å‰åä¸¤ä¸ªç›¸é‚»èŠ‚ç‚¹çš„é”åå¯ä»¥æ’å…¥æ–°èŠ‚ç‚¹ã€‚

### Lock-free data structures

* An algorithm that uses locks is blocking regardless of whether the lock implementation uses spinning or pre-emption

* Non-blocking algorithms are lock-free if some thread is guaranteed to make progress (â€œsystemwide progressâ€)
* Lock-free data structures: non-blocking solution to avoid overheads due to locks
  * But can be tricky to implement
  * Still requires appropriate memory fences on modern relaxed consistency hardware
  * A lock-free design does not eliminate contention

Single reader, single writer unbounded queueï¼š

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/unboundedq.png" style="zoom:80%">

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/unboundedq1.png" style="zoom:75%">

* Tail points to last element added
* Head points to element BEFORE head of queue
* Allocation and deletion performed by the same thread
  * Only push modifies tail & reclaim; only pop modifies head

#### ABA problem

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/aba.png" style="zoom:60%">

ABAé—®é¢˜ï¼Œcompare and swapä¸­å¯èƒ½å¯¼è‡´çš„ä¸€ä¸ªé—®é¢˜ï¼Œä¹Ÿå¯ä»¥é€šè¿‡ç‰ˆæœ¬æˆ³è§£å†³ã€‚

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/lockfreestack.png" style="zoom:75%">

* Maintain counter of pop operations
* Requires machine to support â€œdouble compare and swapâ€ (DCAS) or doubleword CAS
* Could also solve ABA problem with node allocation and/or element reuse policies

Another ABA solution: Hazard Pointers

<img src="https://raw.githubusercontent.com/YijiaJin/Plot/master/hazard.png" style="zoom:75%">

* Node cannot be recycled or reused if matches any hazard pointer

### Reference

[None-Blocking Linked List](https://www.cl.cam.ac.uk/research/srg/netos/papers/2001-caslists.pdf)

[Lock-Free Code: A False Sense of Security](http://www.drdobbs.com/cpp/lock-free-code-a-false-sense-of-security/210600279)

[Common Pitfalls in Writing Lock-Free Algorithms](https://www.memsql.com/blog/common-pitfalls-in-writing-lock-free-algorithms/)